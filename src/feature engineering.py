# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vPlXEu_OlNN3Dj0NFGOh91i_UZF4xbbv
"""

#Import Necessary libraries
import numpy as np
import pandas as pd
import sklearn
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler, KBinsDiscretizer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from scipy import sparse

print("scikit-learn version:", sklearn.__version__)

RANDOM_STATE = 42
EPS = 1e-9

# robust OneHotEncoder
def make_ohe():
    """
    Create an OneHotEncoder that works on both old and new scikit-learn versions.
    New API uses `sparse_output`, older uses `sparse`.
    """
    try:
        # Newer sklearn (>=1.2)
        return OneHotEncoder(handle_unknown="ignore", sparse_output=False)
    except TypeError:
        # Older sklearn (<1.2)
        return OneHotEncoder(handle_unknown="ignore", sparse=False)

# Helper: force dense at the end
def to_dense(X):
    """Convert a possibly sparse output to dense numpy array."""
    return X.toarray() if sparse.issparse(X) else X

# Helper: small audit
def audit_df(name, X, y, feat_names=None, n=3):
    print(f"\n=== {name} ===")
    print("X shape:", X.shape, "| y shape:", y.shape)
    if feat_names is not None:
        try:
            df = pd.DataFrame(to_dense(X), columns=feat_names)
            print(df.head(n))
        except Exception as e:
            print("Could not render head DataFrame:", e)

# Load files
credit_path = "creditcard.csv"
paysim_path = "frauddetection.csv"

cc_raw = pd.read_csv(credit_path)
ps_raw = pd.read_csv(paysim_path)

# Basic coercions & drops
cc_cols = ["Time", "Amount"] + [f"V{i}" for i in range(1, 29)] + ["Class"]
for c in cc_cols:
    if c in cc_raw.columns:
        cc_raw[c] = pd.to_numeric(cc_raw[c], errors="coerce")
cc_raw = cc_raw.dropna(subset=[c for c in cc_cols if c in cc_raw.columns]).drop_duplicates()

ps_num = ["step","amount","oldbalanceOrg","newbalanceOrig","oldbalanceDest","newbalanceDest","isFraud","isFlaggedFraud"]
for c in ps_num:
    if c in ps_raw.columns:
        ps_raw[c] = pd.to_numeric(ps_raw[c], errors="coerce")
ps_raw = ps_raw.dropna(subset=["step","type","amount","oldbalanceOrg","newbalanceOrig","oldbalanceDest","newbalanceDest","isFraud"]).drop_duplicates()


# CREDIT CARD: Feature Engineering
def cc_feature_engineering(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()

    # Stable log transform for heavy-tailed amounts
    out["log_amount"] = np.log1p(out["Amount"].clip(lower=0))

    # Time-of-day features (assuming Time is seconds since start)
    seconds = out["Time"].clip(lower=0)
    hour = ((seconds // 3600) % 24).astype(int)
    out["hour"] = hour
    out["sin_hour"] = np.sin(2 * np.pi * hour / 24.0)
    out["cos_hour"] = np.cos(2 * np.pi * hour / 24.0)
    out["is_night"] = ((hour < 6) | (hour >= 22)).astype(int)
    return out

# Base features used as input to the feature adder
cc_base_feats = ["Time", "Amount"] + [f"V{i}" for i in range(1, 29)]
cc_binary_flags = ["is_night"]
cc_cyclical = ["sin_hour", "cos_hour"]

# We do feature engineering first (without FunctionTransformer, for max compatibility)
cc_fe = cc_feature_engineering(cc_raw[cc_base_feats].copy())

# ColumnTransformer: use robust settings & avoid version pitfalls
cc_transformer = ColumnTransformer(
    transformers=[
        # Amount quantile bins (encode='onehot' returns sparse on some versions)
        ("amount_bins", KBinsDiscretizer(n_bins=8, encode="onehot", strategy="quantile"), ["Amount"]),
        # Standard scale Time + PCA components
        ("std_core", StandardScaler(), ["Time"] + [f"V{i}" for i in range(1, 29)]),
        # Robust scale for Amount & log_amount
        ("robust_amt", RobustScaler(), ["Amount", "log_amount"]),
        # Pass-through cyclical & binary flags
        ("passthrough", "passthrough", cc_binary_flags + cc_cyclical),
    ],
    remainder="drop",
    verbose_feature_names_out=False
)

X_cc = cc_fe
y_cc = cc_raw["Class"].astype(int)
X_cc_tr = cc_transformer.fit_transform(X_cc)
X_cc_tr = to_dense(X_cc_tr)  # force dense for DataFrame / CSV

# Build feature names manually (order aligned with transformers above)
cc_feat_names = []
cc_feat_names += [f"Amount_bin_{i}" for i in range(8)]
cc_feat_names += ["Time"] + [f"V{i}" for i in range(1, 29)]
cc_feat_names += ["Amount_scaled", "log_amount_scaled"]
cc_feat_names += cc_binary_flags + cc_cyclical
cc_feat_names = np.array(cc_feat_names, dtype=object)

audit_df("CreditCard (engineered+transformed)", X_cc_tr, y_cc, cc_feat_names)

# PAYSIM: Feature Engineering (leak-aware)

def paysim_feature_engineering(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()

    # Residual consistency features (leakage-resistant)
    out["delta_orig"] = out["oldbalanceOrg"] - out["amount"] - out["newbalanceOrig"]
    out["delta_dest"] = out["newbalanceDest"] - out["oldbalanceDest"] - out["amount"]

    # Ratio features (before dropping balances)
    out["ratio_amt_oldOrg"]  = out["amount"] / (out["oldbalanceOrg"].abs() + EPS)
    out["ratio_amt_oldDest"] = out["amount"] / (out["oldbalanceDest"].abs() + EPS)

    # Zero-balance flags
    out["is_zero_oldOrg"]  = (out["oldbalanceOrg"].abs() < EPS).astype(int)
    out["is_zero_oldDest"] = (out["oldbalanceDest"].abs() < EPS).astype(int)

    # Type flags
    out["is_transfer_or_cashout"] = out["type"].isin(["TRANSFER", "CASH_OUT"]).astype(int)

    # Temporal cycles from 'step' (assume hours)
    out["hour_of_day"] = (out["step"] % 24).astype(int)
    out["sin_hour"] = np.sin(2*np.pi*out["hour_of_day"]/24.0)
    out["cos_hour"] = np.cos(2*np.pi*out["hour_of_day"]/24.0)
    out["day_index"] = (out["step"] // 24).astype(int)
    out["day_of_week"] = (out["day_index"] % 7).astype(int)
    out["sin_dow"] = np.sin(2*np.pi*out["day_of_week"]/7.0)
    out["cos_dow"] = np.cos(2*np.pi*out["day_of_week"]/7.0)

    # "Unusualness" vs transaction type (robust deviation)
    g = out.groupby("type")["amount"]
    med = g.transform("median")
    mad = 1.4826 * (g.transform(lambda s: (s - s.median()).abs().median()) + EPS)
    out["amt_vs_type_med"] = out["amount"] - med
    out["amt_type_robust_z"] = out["amt_vs_type_med"] / mad

    # Drop raw balance columns to limit deterministic leakage
    out = out.drop(columns=["oldbalanceOrg","newbalanceOrig","oldbalanceDest","newbalanceDest"])
    return out

# Apply feature engineering (no FunctionTransformer for compatibility)
ps_fe_full = paysim_feature_engineering(ps_raw.copy())

# Split X/y
ps_target = "isFraud"
X_ps = ps_fe_full.drop(columns=[ps_target])
y_ps = ps_fe_full[ps_target].astype(int)

# Column groups post-FE
ps_cat = ["type"] if "type" in X_ps.columns else []
ps_flags = ["is_zero_oldOrg","is_zero_oldDest","is_transfer_or_cashout","error_orig","error_dest"]
ps_cyc = ["sin_hour","cos_hour","sin_dow","cos_dow"]
ps_numeric = [
    "step","amount","delta_orig","delta_dest",
    "ratio_amt_oldOrg","ratio_amt_oldDest",
    "amt_vs_type_med","amt_type_robust_z",
    "hour_of_day","day_index","day_of_week"
]

# Some flags (error_orig/dest) are created in FE; ensure presence
for f in ["error_orig","error_dest"]:
    if f not in X_ps.columns:
        # create conservative flags if missing
        X_ps[f] = ((X_ps["delta_orig"].abs() < 1e-9) if "delta_orig" in X_ps.columns else 0).astype(int)

# Transformer
ps_transformer = ColumnTransformer(
    transformers=[
        ("cat", make_ohe(), ps_cat),
        ("num_robust", RobustScaler(), [c for c in ps_numeric if c in X_ps.columns]),
        ("pass_flags", "passthrough", [c for c in (ps_flags + ps_cyc) if c in X_ps.columns]),
        ("amount_bins", KBinsDiscretizer(n_bins=8, encode="onehot", strategy="quantile"), ["amount"] if "amount" in X_ps.columns else []),
    ],
    remainder="drop",
    verbose_feature_names_out=False
)

# Fit-transform
X_ps_tr = ps_transformer.fit_transform(X_ps)
X_ps_tr = to_dense(X_ps_tr)  # force dense

# Build feature names
# OHE names
ohe_names = []
if len(ps_cat) > 0:
    ohe = ps_transformer.named_transformers_["cat"]
    try:
        ohe_names = ohe.get_feature_names_out(ps_cat).tolist()
    except Exception:
        # fallback: categories_ available after fit
        cats = getattr(ohe, "categories_", [[]])[0]
        ohe_names = [f"type_{c}" for c in cats]

# Numeric names (scaled)
num_names = [f"{c}_scaled" for c in ps_numeric if c in X_ps.columns]
# Flags + cycles
flag_cycle_names = [c for c in (ps_flags + ps_cyc) if c in X_ps.columns]
# Amount bins
amount_bin_names = [f"amount_bin_{i}" for i in range(8)] if "amount" in X_ps.columns else []

ps_feat_names = np.array(ohe_names + num_names + flag_cycle_names + amount_bin_names, dtype=object)

audit_df("PaySim (engineered+transformed)", X_ps_tr, y_ps, ps_feat_names)

import numpy as np

print("X_cc_tr dense?", isinstance(X_cc_tr, np.ndarray))
print("X_ps_tr dense?", isinstance(X_ps_tr, np.ndarray))

print("\nClass distributions:")
print("CreditCard:", y_cc.value_counts(normalize=True))
print("PaySim:", y_ps.value_counts(normalize=True))